# intersect 2 sets, passed as 2 members of an array eg.
#  input:
#   $ echo '[[1, 2, 3, 4], [5, 6, 4, 1]]' | jq '. | intersect'
#  output:
#  [1, 4]
def intersect:
    (.[0] | unique) + (.[1] | unique) | sort as $s
    | reduce range(1; $s|length) as $i
        ([]; if $s[$i-1]  == $s[$i] then (. + [$s[$i]]) else . end);

# merge multiple maps in an array into 1 big map
#  input:
#   $ echo '[{"foo": 1}, {"bar": 2}]' | jq '. | merge'
#  output:
#   {"foo": 1, "bar": 2}
def merge: reduce .[] as $sub_map ({}; . + $sub_map);

# make a map with some given value with keys from given array
#  input:
#   $ echo '["foo", "bar"]' | jq '. | mapify(5)'
#  output:
#   {"foo": 5, "bar": 5}
def mapify(v): reduce .[] as $str ({}; . + {($str): v});

# find value of a key recursively
#  input:
#   $ echo '[{"a": {"b" : 4}}, {"c" : {"d": 16}}]' | jq '. | find(.d)'
#  output:
#   16
def find(f): .. | select(type=="object" and f) | f;

# pm_nice
# makes a nice looking compact representation of patch_map
def pm_nice:
  (. | fromjson | to_entries
     | map({key: .key | fromjson | .patchId, value: .value | fromjson})
     | from_entries);

# grpid_s
# generates group-id string from groupId
def grpid_s:
  . | @text "\(.locationId)/\(.superGroupId)/\(.subGroupId)";

def ts_to_date(units_in_s):
  .
  | {s: (. / units_in_s), ms: (. % units_in_s)}
  | .sec_str = (.s | todate)
  | .str_wo_z = (.sec_str | gsub("Z$";""))
  | "\(.str_wo_z).\(.ms)";

def ns_to_date: ts_to_date(1000000000);

def us_to_date: ts_to_date(1000000);

def ms_to_date: ts_to_date(1000);

# pretty brm
def pretty_brm:
  (.
   | {csn: .value.contentSequenceNumber,
      cid: .key.compositeContentId.contentId,
      rsn: .key.representationSequenceNumber,
      lsz: .value.logicalBytes,
      ib: .value.ingestedBytes,
      hib: .value.historicIngestedBytes,
      r: [.value.references[].refType],
      t: (.value.blobRepresentationTimestamp | ms_to_date),
      ct: (.value.contentTimestamp | ms_to_date),
      p: .value.patchId.patchId,
      b:
        (if (.value.baseRef) then
          .value.baseRef
          | {rsn: .representationSequenceNumber,
             c: (.compositeContentId
                 | {cid: .contentId,
                    g: (.groupId | grpid_s)})}
        else
          null
        end)});

# brm_nice
# make a nice looking blob-representation-map
def brm_nice:
  (. | fromjson | to_entries[]
     | {key: .key | fromjson, value: .value | fromjson}
     | pretty_brm);

# brm_verbose
# make a nice looking blob-representation-map
def brm_verbose:
  (. | fromjson | to_entries[]
     | {key: .key | fromjson, value: .value | fromjson, ksn: .key});

# given brm_verbose output
def find_base(ksn):
  map(. | select(.ksn == ksn));

def find_base_rec(ksn):
  (. as $brm | find_base(ksn) as $i
             | if (($i | length) == 0) then
                 []
               else
                 ($i | map(pretty_brm)) +
                   ($i | [map(. | .value.baseRef | tojson as $pksn
                                | $brm | find_base_rec($pksn))[][]])
               end);

# maddr
# map add recursively
#  input:
#   $ echo '[{"foo": 10, "bar": {"a": 1}},
#            {"foo": 4, "quux": 1, "bar": {"a": 2}}]' | jq '. | maddr'
#  output:
#   {"bar": {"a": 3}, "foo": 14, "quux": 1}
def maddr:
  reduce .[] as $m (
    {};
    . as $i | ($i + $m) as $u
            | $u
            | keys
            | map(. as $k | $k
                          | $u[.]
                          | (if (type == "object") then
                               [$i[$k], $m[$k]] | maddr
                             elif (type == "number") then
                               ($i[$k] // 0) + ($m[$k] // 0)
                             elif (type == "array") then
                               [$i + $m] | flatten(1)
                             else
                               error("maddr does not support this type")
                             end) as $v
                          | {key: $k, value: $v})
            | from_entries);


# load_dcbs_csv
# invoke as in $ cat dcbs.csv | qcsv 2 10 17 | jq '. | dcbs_csv_cols'
def load_dcbs_csv:
  . | {
      brm: .[0] | fromjson,
      hm:  .[1] | fromjson,
      pm:  .[2] | fromjson};

def gib:
  ./1024/1024/1024;

# tib
def tib:
  (. | gib)/1024;

# tb
def tb:
  ./1000/1000/1000/1000;

# verbose representation of sharded-group
def scg_verbose:
  .
  | .content_map=(
        .content_map
        | fromjson
        | with_entries({
          key: .key | fromjson | .id,
          value: .value | fromjson}))
  | del(.recent_unique_strings);

def sq2d:
  . | gsub("'"; "\"");

def ne_json(expr):
    if (. == null or . == "" or (. | fromjson | length) == 0) then . else (. | fromjson | expr) end;

def cm_nice:
  .
  | fromjson
  | with_entries({key: .key | fromjson.id, value: .value | fromjson});


def dq2s:
  . | gsub("\""; "'");


def paren_array:
  . | @text "\(.)" | gsub("\\["; "(") | gsub("\\]"; ")");

def find_rsn_base_rec(rsn):
  . as $bv
  | $bv
  | map(select(.key.representationSequenceNumber == rsn))
  | .[0].ksn as $ksn
  | $bv
  | find_base_rec($ksn);


def decode:
    if (. | test("^#*#")) then ("decode_decompress \(.[3:])" | qsh_text) else . end;


def dcbs_row:
  {id: .[0],
   bg_job_cfg: .[1],
   brm_s: .[2],
   cons_s: .[3],
   create_s: .[4],
   cross_lnonce: .[5],
   cross_lowner: .[6],
   cross_spec: .[7],
   del_cids: .[8],
   del_pdir: .[9],
   hm_s: .[10],
   ts: .[11],
   m_lnonce: .[12],
   m_lowner: .[13],
   min_valid_csn: .[14],
   next_csn: .[15],
   next_rsn: .[16],
   pm_s: .[17],
   runiq_strs: .[18],
   rev_specs: .[19],
   schema_ver: .[20],
   seq_no: .[21],
   state_uuid: .[22]};

def empty_string:
    not or (length == 0);

def pre_obj_json:
    if (empty_string) then
       .
    elif (. | fromjson | type == "string") then
       (. | fromjson)
    else
       .
    end;

def dcbs_row_42_pre_obj_corrected:
  {id: .group_id,
   bg_job_cfg: .background_job_config,
   brm_s: (.blob_representation_map | pre_obj_json),
   cons_s: (.consolidate_specs | pre_obj_json),
   create_s: (.create_spec | pre_obj_json),
   cross_lnonce: .cross_lock_nonce,
   cross_lowner: .cross_lock_owner,
   cross_spec: (.cross_spec | pre_obj_json),
   del_cids: (.deleted_content_id_set | pre_obj_json),
   del_pdir: (.deleted_patch_dir_spec_set | pre_obj_json),
   hm_s: (.handle_map | pre_obj_json),
   ts: .internal_timestamp,
   dtbs_on: .is_diff_tree_enabled,
   m_lnonce: .maintenance_lock_nonce,
   m_lowner: .maintenance_lock_owner,
   min_valid_csn: .min_valid_content_sequence_numner,
   next_csn: .next_content_sequence_number,
   next_rsn: .next_representation_sequence_number,
   pm_s: (.patch_map | pre_obj_json),
   runiq_strs: (.recent_unique_strings | pre_obj_json),
   rev_specs: (.reverse_specs | pre_obj_json),
   schema_ver: .schema_version,
   seq_no: .sequence_number,
   state_uuid: .state_uuid};

def dcbs_row_42_raw:
  {group_id: .[0],
   background_job_config: .[1],
   blob_representation_map: .[2],
   consolidate_specs: .[3],
   create_spec: .[4],
   cross_lock_nonce: .[5],
   cross_lock_owner: .[6],
   cross_spec: .[7],
   deleted_content_id_set: .[8],
   deleted_patch_dir_spec_set: .[9],
   handle_map: .[10],
   internal_timestamp: .[11],
   maintenance_lock_nonce: .[12],
   maintenance_lock_owner: .[13],
   min_valid_content_sequence_numner: .[14],
   next_content_sequence_number: .[15],
   next_representation_sequence_number: .[16],
   patch_map: .[17],
   recent_unique_strings: .[18],
   reverse_specs: .[19],
   schema_version: .[20],
   sequence_number: .[21],
   state_uuid: .[22]};

def dcbs_row_50:
  {id: .[0],
   bg_job_cfg: .[1],
   brm_s: .[2],
   cons_s: .[3],
   create_s: .[4],
   cross_lnonce: .[5],
   cross_lowner: .[6],
   cross_spec: .[7],
   del_cids: .[8],
   del_pdir: .[9],
   hm_s: .[10],
   ts: .[11],
   dtbs_on: .[12],
   m_lnonce: .[13],
   m_lowner: .[14],
   min_valid_csn: .[15],
   next_csn: .[16],
   next_rsn: .[17],
   pm_s: .[18],
   runiq_strs: .[19],
   rev_specs: .[20],
   schema_ver: .[21],
   seq_no: .[22],
   state_uuid: .[23]};

def dcbs_json_row_50:
  {id: .group_id,
   bg_job_cfg: .background_job_config,
   brm_s: .blob_representation_map,
   cons_s: .consolidate_specs,
   create_s: .create_spec,
   cross_lnonce: .cross_lock_nonce,
   cross_lowner: .cross_lock_owner,
   cross_spec: .cross_spec,
   del_cids: .deleted_content_id_set,
   del_pdir: .deleted_patch_dir_spec_set,
   hm_s: .handle_map,
   ts: .internal_timestamp,
   dtbs_on: .is_diff_tree_enabled,
   m_lnonce: .maintenance_lock_nonce,
   m_lowner: .maintenance_lock_owner,
   min_valid_csn: .min_valid_content_sequence_numner,
   next_csn: .next_content_sequence_number,
   next_rsn: .next_representation_sequence_number,
   pm_s: .patch_map,
   runiq_strs: .recent_unique_strings,
   rev_specs: .reverse_specs,
   schema_ver: .schema_version,
   seq_no: .sequence_number,
   state_uuid: .state_uuid};

def dcbs_row_42:
  {id: .group_id,
   bg_job_cfg: .background_job_config,
   brm_s: .blob_representation_map,
   cons_s: .consolidate_specs,
   create_s: .create_spec,
   cross_lnonce: .cross_lock_nonce,
   cross_lowner: .cross_lock_owner,
   cross_spec: .cross_spec,
   del_cids: .deleted_content_id_set,
   del_pdir: .deleted_patch_dir_spec_set,
   hm_s: .handle_map,
   ts: .internal_timestamp,
   dtbs_on: .is_diff_tree_enabled,
   m_lnonce: .maintenance_lock_nonce,
   m_lowner: .maintenance_lock_owner,
   min_valid_csn: .min_valid_content_sequence_numner,
   next_csn: .next_content_sequence_number,
   next_rsn: .next_representation_sequence_number,
   pm_s: .patch_map,
   runiq_strs: .recent_unique_strings,
   rev_specs: .reverse_specs,
   schema_ver: .schema_version,
   seq_no: .sequence_number,
   state_uuid: .state_uuid};

def parse_brm_verbose:
  select(.brm_s != "{}")
  | .brm=(.brm_s | fromjson | [brm_verbose])
  | del(.brm_s);

def parse_pm_verbose:
  select(.pm_s != "{}")
  | .pm=(.pm_s | fromjson | pm_nice)
  | del(.pm_s);

def sbs_row:
  {id: .[0],
   close_spec: .[1],
   cm_s: .[2],
   create_s: .[3],
   del_s: .[4],
   hm_s: .[5],
   ts: .[6],
   next_csn: .[7],
   runiq_strs: .[8],
   schema_ver: .[9],
   seq_no: .[10],
   shard_sz: .[11],
   state_uuid: .[12]};

def sbs_row_50:
  {id: .[0],
   close_spec: .[1],
   cm_s: .[2],
   create_s: .[3],
   del_s: .[4],
   hm_s: .[5],
   ts: .[6],
   dtbs_on: .[7],
   next_csn: .[8],
   runiq_strs: .[9],
   schema_ver: .[10],
   seq_no: .[11],
   shard_sz: .[12],
   state_uuid: .[13]};

def sbs_json_row_50:
  {id: .group_id,
   close_spec: .close_spec,
   cm_s: .content_map,
   create_s: .create_spec,
   del_s: .delete_spec,
   hm_s: .handle_map,
   ts: .internal_timestamp,
   dtbs_on: .is_diff_tree_enabled,
   next_csn: .next_content_sequence_number,
   runiq_strs: .recent_unique_strings,
   schema_ver: .schema_version,
   seq_no: .sequence_number,
   shard_sz: .shard_size_in_bytes,
   state_uuid: .state_uuid};

def scgid:
    gsub("_[0-9]+_[0-9]+$";"");

def grp_storage:
    .
    | to_entries
    | map(.key = (.key | fromjson | join("/")))
    | from_entries;

def humanize(u; d; uts):
  def u_str:
    if . > (uts | length) then
      error
    else
      uts[.].u
    end;

  def render(i):
    .
    | {i: . | floor, f: ((. - (. | floor)) | "\(.)" | .[2:4]), u: i | u_str}
    | if .f == "" then "\(.i)\(d)\(.u)" else "\(.i).\(.f)\(d)\(.u)" end;

  def h(i):
    if (. < uts[i].m) and (. >= 1)  then
      render(i)
    elif . < 1 then
      if (i == 0) then
        render(i)
      else
        . * uts[i - 1].m
        | h(i - 1)
      end
    else
      . / uts[i].m
      | h(i + 1)
    end;

  . as $v
  | (uts | map(.u == u) | indices(true)[0]) as $i
  | $v
  | if . then h($i) else . end;

def _size_h(sep):
  humanize(
  "B";
  sep;
  [{u: "B", m: 1024},
   {u: "KiB", m: 1024},
   {u: "MiB", m: 1024},
   {u: "GiB", m: 1024},
   {u: "TiB", m: 1024},
   {u: "PiB", m: 1024},
   {u: "EiB", m: infinite}]);

def size_h: _size_h(" ");

def size_h_no_space:_size_h("");

def count_h:
  humanize(
  "";
  "";
  [{u: "", m: 1000},
   {u: "K", m: 1000},
   {u: "M", m: 1000},
   {u: "B", m: infinite}]);

def time_h(u):
  humanize(
   u;
   "";
   [{u: "ns", m: 1000},
    {u: "us", m: 1000},
    {u: "ms", m: 1000},
    {u: "s", m: 60},
    {u: "m", m: 60},
    {u: "h", m: 24},
    {u: "d", m: infinite}]);

def time_sh:
  time_h("s");

def time_nsh:
  time_h("ns");

def time_msh:
  time_h("ms");

def pow(b; e):
  if (e == 0) then 1 else (b * pow(b; e - 1)) end;

def kb2b:
  . * pow(1000; 1);

def mb2b:
  . * pow(1000; 2);

def gb2b:
  . * pow(1000; 3);

def tb2b:
  . * pow(1000; 4);

def gib2b:
  . * pow(1024; 3);

def mib2b:
  . * pow(1024; 2);

# input [10, "GB"] ... etc
def size_inh:
  . as $e_arr
  | {"bytes": 1,
     "KB": (1 | kb2b),
     "MB": (1 | mb2b),
     "GB": (1 | gb2b),
     "TB": (1 | tb2b)} as $m
  | $m[$e_arr[1]] * $e_arr[0];

# generates graphviz spec for group, used to render a graph for it
# usage:
#  $ cat /tmp/clip.g | jq -r '
#     . as $gd
#     | $gd
#     | draw_grp(
#         $gd | .group_id;
#         "blob_representation_map";
#         "patch_map";
#         false)' > /tmp/g.dot
#  $ dot -Tsvg g.dot -o g.svg
#
# legend:
#   inverted-house     => pinned rep
#   solid oval         => rep with content-ref
#   dashed oval        => rep without content-ref
#   light-blue node    => full rep
#   white node         => inc rep
#   rounded rect-node  => patch
#   node label         => "rsn / csn"
#   tooltip            => rep time
def draw_grp(grp_id; brm_s_key; pm_s_key; show_patches):
    def suffix_semi:
        if . == "" then "" else . + ";" end;
    . as $g
    | $g
    | $g[brm_s_key]
    | [brm_nice]
    | sort_by([.csn, .rsn]) as $brm
    | $g[pm_s_key]
    | pm_nice
    | to_entries
    | map(
        .
        | {
          p: .key,
          lbl: (
            .
            | .value
            | .internalPatchFileStats.physicalBytes
            | size_h
            | "\"\(.)\"")}
        | "\"\(.p)\" [color=grey,style=filled,label=\(.lbl),shape=box,style=rounded]")
    | join(";")
    | suffix_semi as $pm_str
    | $brm
    | map({key: (.rsn | tostring), value: .csn})
    | from_entries as $csn_for
    | $brm
    | map(
      .
      | select(.b)
      | .b_csn = $csn_for[.b.rsn | tostring]
      | .b_str = "\(.b.c.g)/\(.b.rsn)"
      | .c_str = "\(grp_id)/\(.rsn)"
      | .clr_wrt_b = if .b_csn < .csn then "lightblue" else "pink" end
      | .e_clr = if .b.c.g == grp_id then .clr_wrt_b else "red" end
      | .style = "[style=filled,color=\(.e_clr)]"
      | "\"\(.c_str)\" -> \"\(.b_str)\" \(.style)")
    | join(";")
    | suffix_semi as $edge_str
    | $brm
    | map(
      .
      | .ttip = "\"\(.t)\""
      | .is_c = (.r | map(. == "CONTENT") | any)
      | .pinned = (
        .
        | .r
        | map(select(
            . == "CONTENT" or
            . == "INCREMENTAL" or
            . == "CROSS" | not))
        | length > 0)
      | .brd = (
          if .is_c then
            "solid"
          else
            if .pinned then
              "dashed"
            else
              "dotted"
            end
          end)
      | .fill = if (.b | not) then "lightblue" else "white" end
      | .shp = if .pinned then "invhouse" else "oval" end
      | .lbl = "\"\(.rsn) / \(.csn)\""
      | .styl = (
          .
          | ["tooltip=\(.ttip)",
             "style=\"filled,\(.brd)\"",
             "fillcolor=\(.fill)",
             "shape=\(.shp)",
             "label=\(.lbl)"]
          | join(",")
          | "[\(.)]")
      | .node_id = "\(grp_id)/\(.rsn)"
      | "\"\(.node_id)\" \(.styl)")
    | join(";")
    | suffix_semi as $node_tip
    | $brm
    | map(
      .
      | .b
      | select(.)
      | select(.c.g != grp_id)
      | .node_id = "\"\(.c.g)/\(.rsn)\""
      | .ttip = "\"\(.c.g)\""
      | .lbl = "\"CROSS-BASE \(.rsn)\""
      | "\(.node_id) [tooltip=\(.ttip),label=\(.lbl),color=red]")
    | join(";")
    | suffix_semi as $crsb_str
    | $brm
    | map(
      .
      | .brm_id = "\"\(grp_id)/\(.rsn)\""
      | .pm_id = "\"\(.p)\""
      | "\(.brm_id) -> \(.pm_id) [color=grey]")
    | join(";")
    | suffix_semi as $p_ref_str
    | $brm
    | if show_patches then "\($pm_str)\($p_ref_str)" else "" end
    | . as $pstr
    | @text "digraph \"\(grp_id)\" {\($edge_str)\($node_tip)\($crsb_str)\($pstr)}";

# generates graphviz spec for group, used to render a graph for it
# usage:
#  $ cat /tmp/clip.g | jq -r 'draw_dumped_grp(true)' > /tmp/g.dot
#  $ dot -Tsvg g.dot -o g.svg
#
# legend same as draw_grp above
def draw_dumped_grp(show_patches):
    . as $gd
    | $gd
    | draw_grp($gd | .group_id; "blob_representation_map"; "patch_map"; show_patches);

def hm_nice:
  .
  | fromjson
  | with_entries(
     {key: (.key | fromjson.handleId),
      value: (.value | fromjson | .h_ts=(.handleTimestamp | ms_to_date))});

def sg_hm_nice:
  .
  | fromjson
  | with_entries(
     {key: (.key | fromjson.id),
      value: (.value | fromjson)});

def storage_by_grp(loc_map):
  .
  | dcbs_json_row_50
  | select(.id | split("/")[0] | in(loc_map))
  | .brm = (.brm_s | [brm_nice])
  | .pm = (.pm_s | pm_nice)
  | {key: .id,
     value: (.pm
             | map(.internalPatchFileStats.physicalBytes)
             | add )}
  | .value = (if .value then .value else 0 end);

# find-du data to (content, patch, base-content) ids,
#  to be used on input given with '-Rs'
def find_du_pdata:
  .
  | split("\n")
  | map(.
        | select(test("^.+$"))
        | gsub(" +"; " ")
        | split(" ")[1]
        | {d: split("/")}
        | .c = .d[1]
        | .bp = (.d[2] | split("_"))
        | .p = .bp[1]
        | .b = .bp[0]
        | del(.d, .bp)
        | if (.b == "EMPTY") then del(.b) else . end);

def fs_storage_by_grp:
  . | with_entries(.key=(.key | fromjson | join("/")));

def loc_id:
  . | split("/")[0];

def sup_grp_id:
  . | split("/")[1];

def sub_grp_id:
  . | split("/")[2];

def change_grp_key_to_snappable(can_snap_id):
  .
  | .key = (.key | sup_grp_id)
  | .key = (if can_snap_id[.key] then can_snap_id[.key] else .key end);


def group_by_key_and_sum:
  .
  | group_by(.key)
  | map({ key: .[0].key,
          value: (map(.value) | add) })
  | from_entries;

def group_by_key_and_collect:
  .
  | group_by(.key)
  | map({ key: .[0].key,
          value: map(.value) })
  | from_entries;

def group_by_and_collect(k; v):
  .
  | group_by(k)
  | map({ key: (.[0] | k),
          value: map(v) })
  | from_entries;

def sbs_id:
  gsub("_[0-9]+_[0-9]+$";"");

def histo:
  .
  | group_by(.)
  | map({key: .[0], value: length})
  | from_entries;

def snapshot_of(rsn):
  .
  | .brm_s
  | [brm_verbose]
  | map(.
        | select(.key.representationSequenceNumber == rsn)
        | .value.debugInfo.externalId
        | fromjson);

def snap_nice:
  .
  | .lm = (.location_map | fromjson | with_entries(.value=(.value | fromjson)))
  | del(.location_map)
  | .gcm = (.group_id_to_content_id_map | fromjson)
  | del(.group_id_to_content_id_map);


def apply_nested(fn; type_matcher):
  .
  | if (type == "array") then map(apply_nested(fn; type_matcher))
    elif (type == "object") then map_values(apply_nested(fn; type_matcher))
    else . end
  | if (. | type_matcher) then (. | fn) else . end;

def is_array:
  (type == "array");

# to canonicalize json, use: `jq --sort-keys sort_all_arrays`
def sort_all_arrays:
  apply_nested(sort; is_array);

def add_idx:
  reduce .[] as $d ([]; . + [{data: $d, idx: (. | length)}]);

def pretty_repid:
  {rsn: .representationSequenceNumber,
   cid: .compositeContentId.contentId,
   gid: (.compositeContentId.groupId | grpid_s)};

def crs_ref_leak_nice:
  .
  | select(.crossRefLeakReport)
  | .crossRefLeakReport.details
  | map(.
        | .baseRef |= pretty_repid
        | .leakedCrossRefs |= map(pretty_repid));

def sliding(n):
  . as $l
  | [range(0;length - n + 1)]
  | map($l[.:. + n]);

def cdm_instant_to_date:
  .
  | (.epochSecond * 1000 + (.nanoOfSecond / (1000 * 1000)))
  | ms_to_date;

def flr_to_sec: gsub("\\.[0-9]+";"");

def flr_to_min: gsub(":[0-9.]+$";"");

def flr_to_hr: gsub("(:[0-9.]+){2}$";"");

def flr_to_day: gsub("T.+$";"");

def cdm_log:
  .
  | .time = (
      .
      | .instant
      | (.epochSecond * 1000 + (.nanoOfSecond / (1000 * 1000)))
      | ms_to_date);

def s_to_date: ts_to_date(1);

def remove_iso8601_ms:
  .
  | gsub("\\.[0-9]{3}\\+";"+")
  | gsub("\\+0000";"Z");

def iso8601_ts:
  .
  | strptime("%Y-%m-%dT%H:%M:%SZ")
  | mktime;

def simplify_snapapble_id:
  if (.unlikely | length == 0) then
    if (.likely | length == 1) then
      .likely[0]
    else
      .likely
    end
  else
    .
  end;

def sq2d: gsub("'";"\"");

def qtile(q):
  .
  | sort
  | . as $s
  | ((q*length)/100 | floor) as $q_idx
  | $s[if $q_idx >= 1 then $q_idx - 1 else $q_idx end];

def qtile_all(qs):
  . as $a
  | qs
  | sort
  | map(. as $q | {m: "q\($q)", v: ($a | qtile($q))})
  | . + [{m: "cnt", v: ($a | length)}];

def qtile_all_idx(qs):
  .
  | qtile_all(qs)
  | map({key: .m, value: .v})
  | from_entries;

def qtile_all_str(qs; map_fn):
  .
  | qtile_all(qs)
  | map(if (.m | test("^q")) then .v |= map_fn else . end)
  | map("\(.m) = \(.v)")
  | join(", ");

def mean: add / length;

def sq_diff:
  .
  | . as $a
  | $a
  | ($a | mean) as $m
  | $a
  | map(. - $m | . * .)
  | add;

def variance: sq_diff / length;

def sd: variance | sqrt;

def batch_of(n):
  . as $l
  | [range(0;length/n) * n]
  | map($l[.:. + n]);

def groups_of(n): batch_of(n);

def s2h:
  . / pow(60; 2);

def crdb_records_json:
  . as $d
  | ($d | map(select(test("^-[ RECORD [0-9]+ ]$"))) | length) as $n
  | $d
  | batch_of(($d | length / $n))
  | map(.
        | .[1:]
        | map(.
              | gsub(" +"; " ")
              | split(" | ")
              | {key: .[0], value: .[1]})
        | from_entries)[];

def crdb_replicas:
  .
  | gsub("{";"[")
  | gsub("}"; "]")
  | fromjson;

def trim: gsub("^ +| +$"; "");

def esc_re:
  gsub("(?<c>[\\]\\[().?{}^$])"; "\\\(.c)");

def ctrim(cs):
  gsub(cs | map(esc_re) | join("|") | "^(\(.))+|(\(.))+$"; "");

def unpad: trim | gsub(" +"; " ");

def usplit: unpad | split(" ");

def tsplit: trim | split(" ");

def if_n(fn):
  if type == "number" then fn else . end;

def if_s(fn):
  if type == "string" then fn else . end;

def if_o(fn):
  if type == "object" then fn else . end;

def if_l(fn):
  if type == "array" then fn else . end;

def if_e(fn):
  if . then fn else . end;

def if_ne(fn):
  if (. | not) then fn else . end;

def n: tonumber;

def s: "\(.)";

def tkv(k_idx; v_idx):
  {key: .[k_idx],
   value: .[v_idx]};

def attempt(f):
  . as $e
  | $e
  | try (. | f) catch ($e);

# pass 2 maps in form [{.a.}, {.b.}] to compute pair-wise subtraction
#  of the form {.a.} - {.b.}. This assumes values in these maps are all
#  numbers.
def map_diff:
  . as [$a, $b]
  | $a
  | with_entries(.
                 | .key as $k
                 | .value |= (. - $b[$k])
                 | select(.value != 0));

def mean_of_attr(get_fn): map(get_fn) | mean;

def sum_of_attr(get_fn): map(get_fn) | add;

def sq: . * .;

def corr(get_x; get_y):
    . as $d
    | ($d | mean_of_attr(get_x)) as $mx
    | ($d | mean_of_attr(get_y)) as $my
    | $d
    | map(.
          | {rd: .}
          | .xd = ((.rd | get_x) - $mx)
          | .yd = ((.rd | get_y) - $my)
          | .xdyd = (.xd * .yd)
          | .xdsq = (.xd | sq)
          | .ydsq = (.yd | sq)
          | del(.rd))
    | {sum_xdyd: sum_of_attr(.xdyd),
       sum_xdsq: sum_of_attr(.xdsq),
       sum_ydsq: sum_of_attr(.ydsq)}
    | if .sum_xdyd == 0 then
        0
      else
       .sum_xdyd / ((.sum_xdsq | sqrt) * (.sum_ydsq | sqrt))
      end;

def pcap_ms:
  .
  | split(".")
  | {s: (.[0] | strptime("%H:%M:%S")[3:6]),
     us: (.[1] | tonumber)}
  | .s |= (.
           | to_entries
           | map(.value * pow(60; 2 - (.key)))
           | add)
  | .s * 1000 + .us / 1000;

def pcap_tcp_fr_hdr_old:
 .
 | sub(", win.+$";"")
 | sub(":[,0-9ack ]+$";"")
 | split(" ")
 | {t: .[0] | pcap_ms,
    s: .[2],
    d: .[4] | sub(":";""),
    id: .[-2:] | join(" ")};

def pcap_ack:
  if (.[-1] | test("^ack ")) then
    .[-1] | split(" ")[-1] | tonumber
  else
    null
  end;

def pcap_seq:
  if (.[0] | test("^seq ")) then
    .[0]
    | split(" ")[-1]
    | split(":")
    | map(tonumber)
    | if (length == 1) then [.[0], .[0] + 1] else . end
  else
    null
  end;

def pcap_tcp_fr_hdr:
 .
 | sub(", win.+$";"")
 | split(",")
 | {nos: .[1:] | map(trim), flow: .[0] | split(" ")}
 | {t: .flow[0] | pcap_ms,
    s: .flow[2],
    d: .flow[4] | sub(":";""),
    id: .nos[0] | sub(":.+$";""),
    seq: .nos | pcap_seq,
    ack: .nos | pcap_ack,
    nos: .nos}
 | if (.seq | not) then del(.seq) else . end
 | if (.ack | not) then del(.ack) else . end;


def pcap_rtt:
  . as $d
  | $d
  | map(.
        | select(.seq)
        | {key: (.s + .d + (.seq[-1] | tostring)), value: .t})
  | from_entries as $sidx
  | $d
  | map(.
        | select(.ack)
        | .tx_time = $sidx[(.d + .s + (.ack | tostring))]
        | select(.tx_time)
        | .rtt = .t - .tx_time);

def map_keys(fn): with_entries(.key |= (fn));

def dflt(x): if . then . else x end;

# parses golang duration string, returns seconds (numeric)
def golang_durs:
  def split_mul(u):
    . as $acc
    | $acc.r
    | split(u.n; "")
    | if length == 2 then
        {v: ((.[0] | tonumber * u.c) + $acc.v),
         r: .[1]}
      else $acc end;

  . as $s
  | [{n: "h", c: 3600},
     {n: "m(?!s)", c: 60},
     {n: "(?<![mµn])s", c: 1},
     {n: "ms", c: .001},
     {n: "µs", c: .000001},
     {n: "ns", c: .000000001}]
  | reduce .[] as $u (
      {v: 0, r: $s};
      split_mul($u))
  | .v;

def crdb_log_ts:
  .
  | split(" ")[:2]
  | join(" ")
  | .[1:]
  | sub("\\.[0-9]+$";"")
  | strptime("%y%m%d %T");

def vals: to_entries | map(.value);

# echo 1 | \
#   jq --argfile b /tmp/clip.top.100.before \
#      --argfile a /tmp/clip.top.100.after \
#      'compare_stmt_dumps($b; $a; .count)'
def compare_stmt_dumps(before; after; metric_fn):
  def strfy: map({key: (.exec | tojson), value: .}) | from_entries;
  def metric: metric_fn | if . then . else 1 end;
  .
  | before | strfy as $bef
  | after
  | strfy
  | to_entries
  | map(.
        | {exec: .value.exec,
           before: $bef[.key].stats,
           after: .value.stats,
           q: .value.key.query}
        | .val_bef = (.before | metric)
        | .val_aft = (.after | metric)
        | .val_inc = (.val_aft - .val_bef)
        | .inc_pct = ((.val_inc / ([1, .val_bef] | max)) * 100))
  | sort_by(.val_inc)
  | reverse;


#
# delve foo
#
def alt_name(p):
  def nm:
    if .kind == 25 then
      "\(p)/\(.name)<\(.type)>"
    elif .name == "" then
      p
    else
      "\(p)/\(.name)"
    end;
  .
  | if type == "object" then
      . as $o
      | $o
      | nm as $n
      | $o
      | .name = $n
      | if .children then .children |= map(alt_name($n)) else . end
    else
      .
    end;

def m(fn_key; fn_val):
  .
  | map({key: fn_key, value: fn_val})
  | from_entries;

#
# Use in place of `awk` to avoid trouble with '$' and double / single quotes.
#
# Eg.
#
# cat /tmp/clip.f | grep Unexpected | \
#   grep -Po '/var/.+\.json\.gz on .+$' | sed -re 's/ on node//g' | \
#   jq -rR 'interpolate("@"; "rkcl exec @2 \"rm @1\"") | dq2s'
#
def interpolate(refCh; tmpl):
  .
  | split(" ") as $v
  | (.
     | tmpl
     | [match("\(refCh)(\\d+)"; "g")]
     | map(.captures[0].string | tonumber)
     | max) as $max_idx
  | [range($max_idx; 0; -1)]
  | reduce .[] as $i (tmpl; gsub("\(refCh)\($i)"; $v[$i - 1]));


# array to object
# echo '[1, 2, 3]' | jq 'a2o(["one", "two", "three"])'
# returns {"one": 1, "two": 2, "three": 3}
def a2o(attrs):
  .
  | [., attrs]
  | transpose
  | map({key: .[1], value: .[0]})
  | from_entries;


def head(n): .[:n];

def keep(keys):
  . as $e
  | keys
  | map({key: ., value: $e[.]})
  | from_entries;

def b64d: qsh_text("echo \(.) | base64 -d");

def d(msg):
  .
  | {m: msg, d: .}
  | debug
  | .d;

def dexp(msg; exp):
  . as $d
  | {m: msg, d: ($d | exp)}
  | debug
  | $d;

def split_if(criteria):
  reduce .[] as $r (
    [];
    if ($r | criteria) then
      (. + [[$r]])
    else
      if length == 0 then
        [[$r]]
      else
        (.[:-1] + [.[-1] + [$r]])
      end
    end);

def abs: if . < 0 then . * -1 else . end;

def dq: "\"\(.)\"";

# call with cat csv.csv | jq -s 'csv_rows'
def csv_rows:
  .
  | .[0] as $t
  | .[1:] as $d
  | $d
  | map(add_idx | map({key: $t[.idx], value: .data}) | from_entries);

def add_all(attrs):
  .
  | reduce .[] as $r (
      attrs | map({key: ., value: 0});
      map({key: .key, value: (.value + $r[.key])}))
  | from_entries;

def influx0: .results[0].series[0].values;

def sliding_diff:
  .
  | sliding(2)
  | map(.[1] - .[0]);

def time_delta:
  .
  | influx0
  | map(.[0] | iso8601_ts)
  | sliding_diff
  | {mean: mean, sd: sd, count: length};

def influx0_val: influx0 | map(.[1]);

def ctr_meter: influx0_val | sliding_diff;

def tm_ns:
  .
  | influx0_val
  | map(./1000/1000 | ceil);

def influx0_change:
  .
  | influx0_val
  | .[-1] - .[0];

def to_brackets(open; close):
  .
  | gsub(open; "[")
  | gsub(close; "]");

# clean-up host in ansible_o2j
def ah:
  .
  | map(.h |= split(" ")[0]);

# filter data in ansible_o2j output
def adf(t):
  .
  | map(.d |= map(select(t)));

def pctn:
  .
  | sub("%$";"")
  | tonumber;

#rate calculator
#investment
# p = {mat_amt: 2000, pay: 500, pay_yrs: 2, mat_yrs: 4, rate: 1.12, mat_err: 10}
# mat_amt: maturity amount
# mat_err: max acceptable error in maturity amt
# pay: investment per year
# pay_yrs: years to continue investing
# mat_yrs: years to maturity
# rate: rate estimate 1.12 is 12%
#
#p     = plan
#yr    = year
#value = curr value

def dbg_on: $ARGS.named["dbg"] == "true";

def dbg(m):
  . as $o
  | if (dbg_on) then {m: m, o: $o} | debug else . end
  | $o;

def mat_bounded(value; p):
  if (value < (p.mat_amt - p.mat_err)) then
   -1
  elif (value > (p.mat_amt + p.mat_err)) then
    1
  else
    0
  end;

def roi(p; yr; value):
  dbg({v: value, y: yr}) |
  if (yr == p.mat_yrs - 1) then
    dbg("matured") | mat_bounded(value; p)
  elif ((yr >= p.pay_yrs) and (yr < p.mat_yrs - 1)) then
    dbg("not paying") | roi(p; yr + 1; value * p.rate)
  elif (yr < p.pay_yrs) then
    dbg("paying") | roi(p; yr + 1; (value + p.pay) * p.rate)
  else
    error("Invalid state, yr=\(.yr)")
  end;

# {mat_amt: 2000, pay: 500, pay_yrs: 2, mat_yrs: 4, mat_err: 10} | rate_for(1, 2)
def rate_for(min_rate; max_rate):
  .
  | . as $p
  | ((min_rate + max_rate) / 2) as $r
  | $p
  | .rate = $r
  | roi(.; 0; 0) as $ret
  |
  if ($ret == 0) then
    $r
  elif ($ret == 1) then
    rate_for(min_rate; $r)
  elif ($ret == -1) then
    rate_for($r; max_rate)
  else
    error("Invalid state, rate=\($r)")
  end;

# {mat_amt: 2000, pay: 500, pay_yrs: 2, mat_yrs: 4, mat_err: 10} | interest
def interest:
  .
  | rate_for(1.0; 2.0)
  | (. - 1)*100
  | (.*1000 | round/1000)
  | "\(.)%";

def nd(d): if . == null then d else . end;

# Usage: ... | \
#   blkparse -i - -M | \
#   awk '$6 != "m" {print $4" "$6" "$7" "$12" "$13" "$8" "$9" "$10}' | \
#   grep -P '[0-9]+ \+ [0-9]+' | \
#   jq -cR 'blkio_evt' > /tmp/blk_evt.json
#
# Generate cidx json using
# cat /tmp/blk_evt.json | jq -s 'blkio_evt_cidx' > /tmp/c_idx.json
#
# Generate child-device-of-interest index
# cat /tmp/blk_evt.json | \
#    jq -s 'blkio_evt_devidx_soff({"(253,4)": true})' > /tmp/1_soff.json
#
# cat /tmp/blk_evt.json | jq \
#    --slurpfile soff_idx /tmp/1_soff.json \
#    -s 'blkio_evt_relevant_off' > /tmp/2_off.json
# Generate time-report
# cat /tmp/blk_evt.json | jq \
#   --slurpfile c_idx /tmp/c_idx.json \
#   --slurpfile d_idx /tmp/2_off.json \
#   -s 'blkio_tm'
#
# Event's time values are keyed by 'a', 'i' etc,
# a => time between remap -> queued
# q => time between queued -> issued
# ...
# d => time between dispatched -> complete
#
# Eg.
# cat /tmp/sdd1.evt.json | jq \
#    --slurpfile c_idx /tmp/c_idx.json --slurpfile o_idx /tmp/2_off.json \
#    -s 'blkio_tm | select(.)' | jq \
#        -s '.
#            | {a: map(.t.a), q: map(.t.q), i: map(.t.i), d: map(.t.d)}
#            | map_values(qtile_all_str([95,99,100]; time_sh))'
#
# {
#   "a": "q95 = 487.21ns, q99 = 688.19ns, q100 = 6.38us",
#   "q": "q95 = 11.13us, q99 = 18.33us, q100 = 214.63us",
#   "i": "q95 = 23.21us, q99 = 34.15us, q100 = 575.57us",
#   "d": "q95 = 162.27us, q99 = 1.02ms, q100 = 4.02ms"
# }
#
def blkio_evt:
  .
  | split(" ")
  | {
    t: .[0] | tonumber,
    a: .[1],
    op: .[2],
    s_dev: .[3],
    s_off: .[4],
    off_sz: .[5:] | join("")}
  | if .a != "A" then del(.s_dev) else . end;

def blk_evt_match(r):
  $o_idx[0][r.off_sz | split("+")[0]] and $c_idx[0][r.off_sz | split("+")[0]];

def blkio_tm:
  foreach .[] as $r (
    {};

    . as $i
    | $r.off_sz as $k
    | $i
    | if blk_evt_match($r) then
      .
      | if $r.a == "C" then
          {
            A: (.A | del(.[$k])),
            Q: (.Q | del(.[$k])),
            I: (.I | del(.[$k])),
            D: (.D | del(.[$k])),
            G: (.G | del(.[$k])),
            p: (
              $r
              | {
                  a: $i["A"][.off_sz],
                  q: $i["Q"][.off_sz],
                  i: $i["I"][.off_sz],
                  d: $i["D"][.off_sz],
                  c: $r.t}
              | map_values(nd($r.t))
              | {
                  a: (.q - .a),
                  q: (.i - .q),
                  i: (.d - .i),
                  d: (.c - .d)})}
        else
          .
          | (.[$r.a][$r.off_sz] |= $r.t)
          | del(.p)
        end
      else
        $i
      end;

    . as $i
    | select(blk_evt_match($r))
    | if $i.p then ($r | .t = $i.p) | del(.a) else null end)
  | select(.);

# slurp
def blkio_evt_cidx:
  .
  | map(select(.a == "C") | .off_sz | split("+")[0])
  | mapify(true);


#slurp
def blkio_evt_devidx_soff(dev):
  .
  | map(select(.a == "A" and (.s_dev | in(dev))) | .off_sz | split("+")[0])
  | mapify(true);

#slurp
def blkio_evt_relevant_off:
  .
  | map(select(.a == "A" and (.s_off | in($soff_idx[0]))) | .off_sz | split("+")[0])
  | mapify(true);
